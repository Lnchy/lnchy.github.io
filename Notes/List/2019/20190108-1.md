### 爬虫原理
- 原理
    - 模拟浏览器请求来抓取数据

- Java自带实现
    - 使用URL架包实现
- 其他架包实现
    - HttpClient 安卓
    - OKhttp
    - JSoup
        - 导入架包
            ```
            <dependency>
                <groupId>org.jsoup</groupId>
                <artifactId>jsoup</artifactId>
                <version>1.11.3</version>
            </dependency>
            ```
        - 简单使用
            ```
            String url = "http://baidu.com";

            Document doc = Jsoup.connect(url);
            // 传入Cookie
            doc.cookie();
            // 传入数据
            doc.data();
            // 传入头部
            doc.header("User-Agent","");
            // 访问方法
            doc.method(Connection.Method.GET);

            // 查询某个元素
            Element ele = doc.select(".className");
            ```
    - WebMagic
        - 引入架包
            ```
            <dependency>
                <groupId>us.codecraft</groupId>
                <artifactId>webmagic-core</artifactId>
                <version>0.7.3</version>
            </dependency>
            ```
        - 使用
            ```
            public class GithubRepoPageProcessor implements PageProcessor {

                private Site site = Site.me().setRetryTimes(3).setSleepTime(1000).setTimeOut(10000);

                @Override
                public void process(Page page) {
                    page.addTargetRequests(page.getHtml().links().regex("(https://github\\.com/[\\w\\-]+/[\\w\\-]+)").all());
                    page.addTargetRequests(page.getHtml().links().regex("(https://github\\.com/[\\w\\-])").all());
                    page.putField("author", page.getUrl().regex("https://github\\.com/(\\w+)/.*").toString());
                    page.putField("name", page.getHtml().xpath("//h1[@class='entry-title public']/strong/a/text()").toString());
                    if (page.getResultItems().get("name")==null){
                        //skip this page
                        page.setSkip(true);
                    }
                    page.putField("readme", page.getHtml().xpath("//div[@id='readme']/tidyText()"));

                    System.out.println(page);
                }

                @Override
                public Site getSite() {
                    return site;
                }

                public static void main(String[] args) {
                    Spider.create(new GithubRepoPageProcessor()).addUrl("https://github.com/code4craft").thread(5).run();
                }
            }
            ```
    - WebCollector
        - http://www.oschina.net/p/webcollector